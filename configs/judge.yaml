# LLM-as-Judge Configuration
# This file controls all settings for automated evaluation using GPT-4o-mini

# Judge model configuration
judge:
  provider: "openai"                    
  model: "gpt-4o-mini"                  

  # Generation settings
  temperature: 0.0                      
  max_tokens: 200                       

  # Rate limiting (prevents hitting API limits)
  requests_per_minute: 100              
  max_retries: 3                        
  retry_delay_seconds: 2                

# Prompts for the judge
prompts:
  system: |
    You are an expert evaluator for mathematical and scientific questions.
    Your job is to judge whether a model's answer is correct compared to the ground truth.

    Key principles:
    - Consider mathematical equivalence (e.g., 0.5 = 1/2 = 50%)
    - Ignore minor formatting differences (extra spaces, capitalization)
    - Focus on whether the core answer is semantically correct
    - Be lenient with wording but strict with factual accuracy

  
  user_template: |
    Question: {question}

    Ground Truth Answer: {ground_truth}

    Model's Prediction: {prediction}

    Task: Evaluate if the prediction is correct.

    Instructions:
    1. Check if the prediction matches the ground truth semantically
    2. Consider mathematical equivalence (fractions, decimals, percentages)
    3. Ignore formatting differences (spaces, punctuation, capitalization)
    4. The core factual content must be correct

    Respond in EXACTLY this format (no additional text):
    Verdict: [CORRECT or INCORRECT]
    Reasoning: [One concise sentence explaining your decision]

# Output configuration
output:
  save_dir: "experiments/baseline/evaluations"    
  save_raw_responses: true              
