# LLM-as-Judge Configuration
# This file controls all settings for automated evaluation using GPT-4o-mini

# Judge model configuration
judge:
  provider: "openai"                    # API provider (currently only OpenAI)
  model: "gpt-4o-mini"                  # Model name (gpt-4o-mini is cheap and good)
  api_key_env: "OPENAI_API_KEY"         # Environment variable containing your API key

  # Generation settings
  temperature: 0.0                      # 0.0 = deterministic (same input always gives same output)
  max_tokens: 200                       # Maximum response length (verdict + reasoning)

  # Rate limiting (prevents hitting API limits)
  requests_per_minute: 100              # Max 100 requests per minute (safe for most tiers)
  max_retries: 3                        # Retry up to 3 times on failure
  retry_delay_seconds: 2                # Initial wait time between retries (doubles each time)

# Prompts for the judge
# These tell GPT-4o-mini how to evaluate predictions
prompts:
  # System prompt: Sets the judge's role and behavior
  system: |
    You are an expert evaluator for mathematical and scientific questions.
    Your job is to judge whether a model's answer is correct compared to the ground truth.

    Key principles:
    - Consider mathematical equivalence (e.g., 0.5 = 1/2 = 50%)
    - Ignore minor formatting differences (extra spaces, capitalization)
    - Focus on whether the core answer is semantically correct
    - Be lenient with wording but strict with factual accuracy

  # User prompt template: Format for each evaluation
  # Placeholders {question}, {ground_truth}, {prediction} will be filled in
  user_template: |
    Question: {question}

    Ground Truth Answer: {ground_truth}

    Model's Prediction: {prediction}

    Task: Evaluate if the prediction is correct.

    Instructions:
    1. Check if the prediction matches the ground truth semantically
    2. Consider mathematical equivalence (fractions, decimals, percentages)
    3. Ignore formatting differences (spaces, punctuation, capitalization)
    4. The core factual content must be correct

    Respond in EXACTLY this format (no additional text):
    Verdict: [CORRECT or INCORRECT]
    Reasoning: [One concise sentence explaining your decision]

# Output configuration
output:
  save_dir: "experiments/evaluation"    # Where to save evaluation results
  save_raw_responses: true              # Keep full judge responses for debugging
